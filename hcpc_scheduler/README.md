# HCPC Priority Scheduler / HCPC 优先级调度器

**HCPC Priority Scheduler** --- A scheduler designed for GPU and CPU task allocation in the Apollo Autonomous Driving System. It analyzes random DAG graphs, computes node weights based on user-defined inputs, identifies critical paths, and outputs detailed resource allocation information for scheduling research.

**HCPC 优先级调度器** --- 针对 Apollo 自动驾驶系统中的 GPU 与 CPU 任务资源调度而设计的调度器。该调度器分析随机生成的 DAG 图，根据用户预设的节点权重计算，并识别关键路径，输出详细的资源分配信息，用于调度研究。

---

## Table of Contents / 目录
- [Overview / 简介](#overview--简介)
- [Input Description / 输入说明](#input-description--输入说明)
- [Algorithm Process / 算法流程](#algorithm-process--算法流程)
- [Output Example / 输出示例](#output-example--输出示例)
- [Usage / 使用方法](#usage--使用方法)
- [Dependencies and Environment / 依赖与环境要求](#dependencies-and-environment--依赖与环境要求)
- [Note / 备注](#note--备注)

---

## Overview / 简介

This algorithm analyzes random DAG graphs generated by the `dag-gen-rnd` module. Users manually assign weights to nodes (e.g., setting the start and sink nodes to 0 to indicate no load), after which the algorithm parses the graph to determine the critical path, maximum number of GPU partitions, and detailed scheduling information for CPU and GPU tasks.

该算法用于分析由 `dag-gen-rnd` 模块生成的随机 DAG 图。用户需手动为各节点设定权重（例如，将起始节点和终止节点的权重设为 0，表示无负载），算法随后解析图结构，识别关键路径，计算 GPU 最大分区数量，并输出 CPU 与 GPU 任务的详细调度信息。

---

## Input Description / 输入说明

- **Task Data / 任务属性数据**

```python
tasks_data = [
    (1, {'rank': 0, 'task_type': 'CPU'}),
    # Other tasks...
]
```
Each tuple contains a task ID and a dictionary of task attributes.

- **DAG Edge List / DAG 边列表**

```python
edges = [
    (1, 4, {}),
    # Other edges...
]
```
Each tuple represents an edge with source, target, and optional attributes.

- **Node Weights / 节点权重**

Users must manually assign weights to nodes. For example:

```python
node_weight = {}
node_weight[1] = 0      # Start node, set to 0
node_weight[23] = 0     # Sink node, set to 0
node_weight[2] = 1
node_weight[3] = 5
# …
```

---

## Algorithm Process / 算法流程

### 1. Preprocessing and Weight Assignment / 预处理与权重定义

Users manually input the weights for each node, ensuring that the start and sink nodes are set to 0.

### DAG Graph Analysis / DAG 图分析

The algorithm parses the DAG graph, identifies the critical path, computes the total project duration, and groups nodes into Capacity Providers (CP groups) with associated F and G sets, as well as potential parallel regions (R).

算法解析 DAG 图，识别关键路径、计算项目总工期，并将节点合并生成 Capacity Providers（CP 组）及各自的 F 与 G 集合，同时确定潜在的并行区域 R。

### Resource Management and Scheduling Output / 资源管理与调度输出

The algorithm outputs node weights, critical paths, GPU partitions, GPU task dependencies, and CPU task priorities.

算法输出节点权重、关键路径、项目总工期、GPU最大分区数量、GPU任务依赖关系、独立GPU任务和 CPU 任务优先度分配结果。

---

## Output Example / 输出示例
```python
======== 节点权重 (node_weight) ========
  节点 1: 0
  节点 2: 1
  节点 3: 5
  节点 4: 4
  节点 5: 4
  节点 6: 3
  节点 7: 2
  节点 8: 9
  节点 9: 2
  节点 10: 10
  节点 11: 7
  节点 12: 1
  节点 13: 1
  节点 14: 2
  节点 15: 4
  节点 16: 4
  节点 17: 9
  节点 18: 10
  节点 19: 1
  节点 20: 9
  节点 21: 4
  节点 22: 9
  节点 23: 0

======== 关键路径 & 总工期 ========
  关键路径: [1, 3, 10, 13, 18, 20, 23]
  总工期:   35

======== 合并后的 Capacity Providers (CP groups) ========
  CP组 0: [1, 3]
  CP组 1: [10]
  CP组 2: [13]
  CP组 3: [18, 20]
  CP组 4: [23]

======== 各 CP 对应的 F 与 G ========
  CP组 0:
    F(CP_0) = {4, 5}
    G(CP_0) = {2, 6, 7, 9, 11, 16}
  CP组 1:
    F(CP_1) = {8, 9, 2, 6}
    G(CP_1) = {7, 11, 12, 16}
  CP组 2:
    F(CP_2) = {11, 7}
    G(CP_2) = {16, 12, 14}
  CP组 3:
    F(CP_3) = {12, 14, 15, 16, 17, 19, 21, 22}
    G(CP_3) = set()
  CP组 4:
    F(CP_4) = set()
    G(CP_4) = set()

======== 每个 CP组 的潜在并行区域 (R) ========
  CP组 0 的 R: {1, 2, 3, 4, 5, 6, 7, 9, 11, 16}
  CP组 1 的 R: {2, 6, 7, 8, 9, 10, 11, 12, 16}
  CP组 2 的 R: {16, 7, 11, 12, 13, 14}
  CP组 3 的 R: {12, 14, 15, 16, 17, 18, 19, 20, 21, 22}
  CP组 4 的 R: {23}

======== 各 R 中的 GPU 任务数量统计 ========
  CP组 0 的 R 中 GPU 任务数量: 5
  CP组 1 的 R 中 GPU 任务数量: 6
  CP组 2 的 R 中 GPU 任务数量: 5
  CP组 3 的 R 中 GPU 任务数量: 7
  CP组 4 的 R 中 GPU 任务数量: 0

======== GPU 最大分区数量 ========
  7

======== 所有 GPU 任务集合 ========
  {3, 5, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 22}

======== GPU 依赖关系 (GPU -> GPU祖先) ========
  GPU 任务 7 依赖的 GPU 祖先: {3, 5}
  GPU 任务 8 依赖的 GPU 祖先: {5}
  GPU 任务 10 依赖的 GPU 祖先: {3, 5}
  GPU 任务 11 依赖的 GPU 祖先: {3, 5, 7}
  GPU 任务 12 依赖的 GPU 祖先: {10, 3, 5}
  GPU 任务 14 依赖的 GPU 祖先: {8, 3, 5}
  GPU 任务 18 依赖的 GPU 祖先: {3, 5, 7, 8, 10, 11}
  GPU 任务 19 依赖的 GPU 祖先: {3, 5, 7, 8, 10, 11, 14}
  GPU 任务 21 依赖的 GPU 祖先: {3, 5, 7, 8, 10, 11, 18}
  GPU 任务 22 依赖的 GPU 祖先: {3, 5, 7, 8, 10, 11, 12, 14, 16, 18}

======== 独立GPU任务 (无GPU祖先) ========
  {16, 3, 5}

======== 独立GPU任务的最早开始时间 (initial_time) ========
initial_time = {
    3: 0,
    5: 0,
    16: 0,
}

======== 两GPU间"最大CPU路径" 结构性数据 (gpu_deps -> gpu_path_map) ========
  {7: {3: {'cpu_path_length': 0, 'cpu_nodes': []}, 5: {'cpu_path_length': 0, 'cpu_nodes': []}}, 8: {5: {'cpu_path_length': 0, 'cpu_nodes': []}}, 10: {3: {'cpu_path_length': 0, 'cpu_nodes': []}, 5: {'cpu_path_length': 0, 'cpu_nodes': []}}, 11: {3: {'cpu_path_length': 0, 'cpu_nodes': []}, 5: {'cpu_path_length': 0, 'cpu_nodes': []}, 7: {'cpu_path_length': 0, 'cpu_nodes': []}}, 12: {3: {'cpu_path_length': 0, 'cpu_nodes': []}, 5: {'cpu_path_length': 0, 'cpu_nodes': []}, 10: {'cpu_path_length': 0, 'cpu_nodes': []}}, 14: {3: {'cpu_path_length': 2, 'cpu_nodes': [9]}, 5: {'cpu_path_length': 0, 'cpu_nodes': []}, 8: {'cpu_path_length': 0, 'cpu_nodes': []}}, 18: {3: {'cpu_path_length': 3, 'cpu_nodes': [9, 13]}, 5: {'cpu_path_length': 1, 'cpu_nodes': [13]}, 7: {'cpu_path_length': 0, 'cpu_nodes': []}, 8: {'cpu_path_length': 1, 'cpu_nodes': [13]}, 10: {'cpu_path_length': 1, 'cpu_nodes': [13]}, 11: {'cpu_path_length': 0, 'cpu_nodes': []}}, 19: {3: {'cpu_path_length': 12, 'cpu_nodes': [9, 13, 17]}, 5: {'cpu_path_length': 10, 'cpu_nodes': [13, 17]}, 7: {'cpu_path_length': 9, 'cpu_nodes': [17]}, 8: {'cpu_path_length': 10, 'cpu_nodes': [13, 17]}, 10: {'cpu_path_length': 10, 'cpu_nodes': [13, 17]}, 11: {'cpu_path_length': 9, 'cpu_nodes': [17]}, 14: {'cpu_path_length': 9, 'cpu_nodes': [17]}}, 21: {3: {'cpu_path_length': 3, 'cpu_nodes': [9, 13]}, 5: {'cpu_path_length': 1, 'cpu_nodes': [13]}, 7: {'cpu_path_length': 0, 'cpu_nodes': []}, 8: {'cpu_path_length': 1, 'cpu_nodes': [13]}, 10: {'cpu_path_length': 1, 'cpu_nodes': [13]}, 11: {'cpu_path_length': 0, 'cpu_nodes': []}, 18: {'cpu_path_length': 0, 'cpu_nodes': []}}, 22: {3: {'cpu_path_length': 12, 'cpu_nodes': [9, 13, 17]}, 5: {'cpu_path_length': 10, 'cpu_nodes': [13, 17]}, 7: {'cpu_path_length': 9, 'cpu_nodes': [17]}, 8: {'cpu_path_length': 10, 'cpu_nodes': [13, 17]}, 10: {'cpu_path_length': 10, 'cpu_nodes': [13, 17]}, 11: {'cpu_path_length': 9, 'cpu_nodes': [17]}, 12: {'cpu_path_length': 4, 'cpu_nodes': [15]}, 14: {'cpu_path_length': 9, 'cpu_nodes': [17]}, 16: {'cpu_path_length': 0, 'cpu_nodes': []}, 18: {'cpu_path_length': 0, 'cpu_nodes': []}}}

======== CPU 任务优先度分配结果 ========
  CPU任务 1 => 优先度 100
  CPU任务 2 => 优先度 94
  CPU任务 4 => 优先度 96
  CPU任务 6 => 优先度 95
  CPU任务 9 => 优先度 93
  CPU任务 13 => 优先度 99
  CPU任务 15 => 优先度 91
  CPU任务 17 => 优先度 92
  CPU任务 20 => 优先度 98
  CPU任务 23 => 优先度 97

======== 所有输出完毕 ========
```
## Usage / 使用方法

1. Place the `hcpc_priority_scheduler.py` file into your project module.
2. Ensure the `dag-gen-rnd` module generates the required DAG data.
3. Based on the generated DAG diagram, modify the `tasks_data`, `edges`, `node_weight` in the file.
4. run the `hcpc_priority_scheduler.py`

```python

# Example data
tasks_data = [(1, {'rank': 0, 'task_type': 'CPU'})]
edges = [(1, 4, {})]
node_weight = {1: 0, 2: 1, 3: 5, 23: 0} # and so on...

python3 hcpc_priority_scheduler.py
```

---

## Dependencies and Environment / 依赖与环境要求

- Python 3.6 or higher
- Related libraries as indicated in your code.

---

## Note / 备注

- Extend input structures as needed.
- Conduct thorough testing before integrating into Apollo Autonomous Driving System.

请在正式集成前进行充分的单元与集成测试。